---
title: "clasification"
output: html_document
---

```{r setup, include=FALSE}
source('01_setup.R')
load('track_part_final.RData')
```

Ahora tenemos un dataset de canciones con una serie de generos (7), y buscamos ver que variables diferencian mejor los generos. Primero, hagamos una exploracion para ver cuantos clusters nos da el indice CH y el silhouette.

```{r number of clusters}
#hago el numero de clusters para 3 metodos: kmeans, single, complete
 CH_graph <- c()
k <- c(2:10)
for (i in 2:length(k)) {
  CH_single <- track_part_final %>% select(-c("track.id","genres")) %>% NbClust(min.nc = i, max.nc = i, method = "single", index = "ch")
  CH_single <- t(CH_single$Best.nc)
  colnames(CH_single) <- c("Number_Clusters","Single")
  CH_complete <- track_part_final %>% select(-c("track.id","genres")) %>% NbClust(min.nc = i, max.nc = i, method = "complete", index = "ch")
  CH_complete <- t(CH_complete$Best.nc)
  colnames(CH_complete) <- c("Number_Clusters","Complete")

  CH_kmeans <- track_part_final %>% select(-c("track.id","genres")) %>% NbClust(min.nc = i, max.nc = i, method = "kmeans", index = "ch")
  CH_kmeans <- t(CH_kmeans$Best.nc)
  colnames(CH_kmeans) <- c("Number_Clusters","K means")
  aux <- cbind(CH_kmeans,CH_single[2],CH_complete[2])
  CH_graph <- rbind(CH_graph,aux)
  
}
colnames(CH_graph) <- c("Number_Clusters","K.means","Single","Complete")
CH_graph <- data.frame(CH_graph)
CH_plot <- ggplot(CH_graph) + geom_point(mapping = aes(Number_Clusters,K.means),color = 'darkblue',size = 3) + geom_line(aes(Number_Clusters,K.means),color = 'cyan') + 
  geom_point(mapping = aes(Number_Clusters,Single),color = 'darkred',size = 3) + geom_line(aes(Number_Clusters,Single),color = 'red') + 
  geom_point(mapping = aes(Number_Clusters,Complete),color = 'darkgreen',size = 3) + geom_line(aes(Number_Clusters,Complete),color = 'green') + xlab('Número de Clusters') + ylab('Índice CH') + theme_bw()



S_graph <- c()
for (i in 2:length(k)) {
  S_single <- track_part_final %>% select(-c("track.id","genres")) %>% NbClust(min.nc = i, max.nc = i, method = "single", index = "silhouette")
  S_single <- t(S_single$Best.nc)
  colnames(S_single) <- c("Number_Clusters","Single")
  S_complete <- track_part_final %>% select(-c("track.id","genres")) %>% NbClust(min.nc = i, max.nc = i, method = "complete", index = "silhouette")
  S_complete <- t(S_complete$Best.nc)
  colnames(S_complete) <- c("Number_Clusters","Complete")

  S_kmeans <- track_part_final %>% select(-c("track.id","genres")) %>% NbClust(min.nc = i, max.nc = i, method = "kmeans", index = "silhouette")
  S_kmeans <- t(S_kmeans$Best.nc)
  colnames(S_kmeans) <- c("Number_Clusters","K means")
  aux <- cbind(S_kmeans,S_single[2],S_complete[2])
  S_graph <- rbind(S_graph,aux)
  colnames(S_graph) <- c("Number_Clusters","K means","Single","Complete")
}
colnames(S_graph) <- c("Number_Clusters","K.means","Single","Complete")
S_graph <- data.frame(S_graph)
S_plot <- ggplot(S_graph) + geom_point(mapping = aes(Number_Clusters,K.means),color = 'darkblue',size = 3) + geom_line(aes(Number_Clusters,K.means),color = 'cyan') + 
  geom_point(mapping = aes(Number_Clusters,Single),color = 'darkred',size = 3) + geom_line(aes(Number_Clusters,Single),color = 'red') + 
  geom_point(mapping = aes(Number_Clusters,Complete),color = 'darkgreen',size = 3) + geom_line(aes(Number_Clusters,Complete),color = 'green') + xlab('Número de Clusters') + ylab('Índice de Silueta') + 
  theme_bw()

#no se poner leyendas para cada grafica: verde complete
#                                        rojo single
#                                        azul kmeans


CH_plot+S_plot
```
Se observa que la tendencia es a pocos clusters. COmo se tiene información externa de que hay 7 generos hay dos aproaches: buscar por que hace pocos clusters y como esta creando la division o forzar a que encuentre 7 clusters estudiando que esta creando esa union de grupos. 
De momento voy a ir por la segunda opcion. Lo primero es hacer un k means


Vamos a realizar un primer clustering con k = 7 y usando jerarquico con single, kmeans y dbscan. Para dbscan se usarán Minpts 20 y un epsilon de manera que la cantidad de clusters sea cercana a 7.

```{r clustering}


k <- 7 #num clusters
km <- track_part_final %>% select(-c("track.id","genres")) %>% kmeans(k,nstart = 15)
single <- track_part_final %>% select(-c("track.id","genres")) %>% dist() %>% hclust(method = 'single') %>% 
  cutree(k)
complete<- track_part_final %>% select(-c("track.id","genres")) %>% dist() %>% hclust(method = 'complete') %>%
  cutree(k)
#busco una estimacion de un buen epsilon con knn
#FALLO no se me pinta la knn graph bien y no entiendo
#haciendolo sin ggplot me salia mas o menos 0.2 el cambio de pendiente
plot_knn <- track_part_final %>% select(-c("track.id","genres")) %>%  kNNdist(k = 1) %>% sort()
N <- c(1:length(plot_knn))
df <- data.frame(N,plot_knn)
knn_p <- ggplot(df,aes(N,plot_knn)) + geom_point() + theme_bw()
knn_p


dbs <- track_part_final %>% select(-c("track.id","genres")) %>% dbscan(eps = 0.12, minPts = 5)

#OJO
#esto es bastante estupido, al final siempre acabo cogiendo el epsilon y minpts que me da la gana para que cuadre
#fallan todos los criterios


results <- track_part_final %>% select(c("track.id","genres")) %>% mutate(km = factor(km$cluster),single = 
                                                                            factor(single), 
                                                                          complete = factor(complete), 
                                                                            dbs = factor(dbs$cluster))
summary(results)

#km_bars <- ggplot(results,aes(km,group = genres, fill = genres)) + geom_bar(position="dodge")+theme_bw() + 
  #labs(title = 'K-means')
km_bars <- ggplot(results,aes(km,group = genres, fill = genres)) + geom_bar()+theme_bw() + 
  labs(title = 'K-means') +
  facet_grid(~genres)
single_bars <- ggplot(results,aes(single,group = genres, fill = genres)) + geom_bar()+theme_bw() + 
  labs(title = 'single') +
  facet_grid(~genres)
complete_bars <- ggplot(results,aes(complete,group = genres, fill = genres)) + geom_bar()+theme_bw() + 
  labs(title = 'Complete') +
  facet_grid(~genres)
dbs_bars <- ggplot(results,aes(dbs,group = genres, fill = genres)) + geom_bar()+theme_bw() + 
  labs(title = 'DBSCAN') +
  facet_grid(~genres)
km_bars
single_bars
complete_bars
dbs_bars
```
Con esta primera clasificación, el dbscan es un desastre. También vemos como el single mete casi todo en el grupo 1, esto es consecuencia del mencionado chain effect y nos hace deducir que no es idoneo para estos datos. k means y complete parecen mas decentes, asi que seguiremos con esos. Sin embargo, aunque la musica clasica esta siendo diferenciada, el resto de genéros no están distribuidos de forma tan clara. vamos a buscar maneras de distinguirlos.

Vamos a hacer como que el dbscan no existe de momento porque si no esto no va ningun lado. Me centro en entender que hace que todos los generos menos la musica clásico se vean similares. Para ello a separar en musica clasica y no clasica como con el rock y metal al principio

```{r classical music difference}
difference_classical <- track_part_final %>% mutate(generic_genre = as.numeric(genres == 'classical'))
difference_classical <- difference_classical %>% mutate(generic_genre = as.factor(generic_genre))
other <- difference_classical %>% filter(generic_genre == 0) %>% select(-'generic_genre')
sapply(other,var)
# danceability           energy         loudness      speechiness  acousticness 
# 0.025819539      0.022333152      0.004291213      0.005216687   0.019094499   
#instrumentalness         liveness          valence            tempo      key 
#   0.072538149      0.016803100      0.056286858      0.031588148      0.097577745 
#         mode           fifths 
#      0.245466814      0.089987843
#parece que las variables sppechiness y loudness tienen una varianza muy baja, vamos a compararlas
speech <- ggplot(difference_classical,aes(speechiness,group = generic_genre,color = generic_genre)) + geom_density() + theme_bw()
loud <- ggplot(difference_classical,aes(loudness,group = generic_genre,color = generic_genre)) + geom_density() + theme_bw()
speech+loud
```
Se observa que estas dos variables estan muy concentradas para los generos a diferenciar. Para la musica clásica, la loudness tiene a ser baja pero dentro de una gama muy amplia, mientras que el speechiness siempre es bajisimo. Sin mebargo, el speechiness en general para todas las variables es muy bajo, por lo que no parece una gran variable para el clustering. Lo mismo para la loudness, parece que no es algo que diferencia los generos. Sin embargo, podría see la variable clave para diferenciar la musica clásica del resto.
Nota: Liveness y acousticness son las siguientes variables a estudiar para ver si ayudan a confundir los generos o no (varianzas del orden de 0.01-0.02).

Vamos a realizar un nuevo clustering, esta vez eliminando speechiness y loudness
```{r clustering2}
df_aux <- track_part_final %>% select(-c("track.id","genres","speechiness", "loudness"))
k <- 7
Km <- df_aux %>% kmeans(k,iter.max = 20)
comp <- df_aux %>% dist() %>% hclust(method = 'complete') %>% cutree(k)

results2 <- track_part_final %>% select(c("track.id","genres")) %>% mutate(km = factor(km$cluster),complete = factor(comp))

summary(results2)

#km_bars <- ggplot(results,aes(km,group = genres, fill = genres)) + geom_bar(position="dodge")+theme_bw() + 
  #labs(title = 'K-means')
km_bars2 <- ggplot(results2,aes(km,group = genres, fill = genres)) + geom_bar()+theme_bw() + 
  labs(title = 'K-means') +
  facet_grid(~genres)

complete_bars2 <- ggplot(results2,aes(complete,group = genres, fill = genres)) + geom_bar()+theme_bw() + 
  labs(title = 'Complete') +
  facet_grid(~genres)

km_bars2
complete_bars2

```

Vemos una mejor proporción, sobretodo en el complete. Se ve como la mayoría del trap y el regaetton se van al grupo 1. Se podría decir que con estas features los generos que siguen confundiendose son edm permanent wave pop y rock. Vamos a ver como se comportan los datos en función de liveness y acousticness

```{r liveness acousticness}
ggplot(track_part_final %>% distinct(track.id,genres,acousticness,liveness), aes(acousticness, liveness,color = genres)) + geom_point() + theme_bw()
```

Se observa como la acousticness es otra feature clave para reconocer la musica clasica, mientras que la liveness no aporta practicamente nada. Por tanto ahora vamos a eliminar liveness y ver que pasa.

```{r clustering3}
df_aux <- track_part_final %>% select(-c("track.id","genres","speechiness", "loudness","liveness"))
k <- 7
Km <- df_aux %>% kmeans(k,iter.max = 20)
comp <- df_aux %>% dist() %>% hclust(method = 'complete') %>% cutree(k)

results3 <- track_part_final %>% select(c("track.id","genres")) %>% mutate(km = factor(km$cluster),complete = factor(comp))

summary(results3)

#km_bars <- ggplot(results,aes(km,group = genres, fill = genres)) + geom_bar(position="dodge")+theme_bw() + 
  #labs(title = 'K-means')
km_bars3 <- ggplot(results3,aes(km,group = genres, fill = genres)) + geom_bar()+theme_bw() + 
  labs(title = 'K-means') +
  facet_grid(~genres)

complete_bars3 <- ggplot(results3,aes(complete,group = genres, fill = genres)) + geom_bar()+theme_bw() + 
  labs(title = 'Complete') +
  facet_grid(~genres)

km_bars3
complete_bars3

```
Se observa como kmeans empieza a confundir otra vez variables. Esto nos dice que hasta aqui llega kmeans. Para seguir usando kmeans podria realizarse comparando entre menos generos (ir eliminando una vez clasificados).
El complete deja en el 6 y 7 musica clasica, mientras que en el 1 2 3 regaeton trap permanent wave y rock, ademas el 4 y 5 son de edm y pop sobretodo, pero no se concetran ahi. Esto nos dice que hay problemas para encontrar una feature caracterísitca del edm o del pop con esta muestra. VAmos a volver a decidir posibles features problematicas.

```{r exxplore}
sapply(track_part_final %>% select(-c("track.id","genres")), sd)
#    danceability           energy         loudness      speechiness     acousticness instrumentalness 
#      0.19503962       0.26531982       0.18051483       0.06995298       0.29993209       0.32853221 
#        liveness          valence            tempo           fifths 
#      0.12585540       0.25299306       0.19097270       0.29897124 
ggplot(track_part_final %>% distinct(track.id,genres,energy,instrumentalness), aes(energy, instrumentalness,color = genres)) + geom_point() + theme_bw()

ggplot(track_part_final %>% distinct(track.id,genres,valence), aes(valence,color = genres)) + geom_density() + theme_bw()

ggplot(track_part_final %>% distinct(track.id,genres,fifths), aes(fifths,color = genres)) + geom_density() + theme_bw()
```

Cosas que se pueden deducir:
  la insturmentalness puede ser buena para distinguir edm clasica y el resto
  la energía es baja para la clasica y variada para la mayoria (dentro de valores altos)
  valencia muy baja para la clasica, puede que sea la clave para diferenciar el trap del resto
  fifths muestra que casi todos os generos tienden a dos zonas mientras que edm y pop se concentran en el centro        (puede ser util para agruparlos)
  
  Vamos a hacer otro intento de distinguir el edm. Para ello usamos instrumentalness y fifths.
  
```{r edm distinto}
k <- 7
km <- track_part_final %>% select(c("instrumentalness","fifths")) %>% kmeans(k,nstart = 20)
comp <- track_part_final %>% select(c("instrumentalness","fifths")) %>% dist() %>% hclust(method = 'complete') %>%
  cutree(k)
results4 <- track_part_final %>% mutate(km = factor(km$cluster),complete = factor(comp))

summary(results4)

#km_bars <- ggplot(results,aes(km,group = genres, fill = genres)) + geom_bar(position="dodge")+theme_bw() + 
  #labs(title = 'K-means')
km_bars4 <- ggplot(results4,aes(instrumentalness, fifths,group = km, color = km,size = genres)) + geom_point()+theme_bw() + 
  labs(title = 'K-means')

complete_bars4 <- ggplot(results4,aes(instrumentalness, fifths,group = complete, color = complete, size = genres)) + geom_point()+theme_bw() + 
  labs(title = 'Complete')
km_bars4
complete_bars4

  
```
No hay manera de ver mas. Esto es probablemente a que con pocos datos y todos entre el 0y 1 se superponen y dificultan encontrar clusters. El siguiente paso será tratar de ver si se pueden aislar determinados generos clasificando en una variable o dos y asi realizar una clasificación por etapas. 

NEXT:
Para seguir, repasar features key para identificar algun genero y realizar primero pruebas con eso (clutering con k=2,3 y ver si aislas ese genero).




FUTURO:
Para interpretar los datos finales mirar cosas de matrices de confusion.
